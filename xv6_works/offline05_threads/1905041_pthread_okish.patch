diff --git a/Makefile b/Makefile
index 39a99d7..dc1525e 100644
--- a/Makefile
+++ b/Makefile
@@ -125,14 +125,17 @@ UPROGS=\
 	$U/_ln\
 	$U/_ls\
 	$U/_mkdir\
+	$U/_producer_consumer\
 	$U/_rm\
 	$U/_sh\
 	$U/_stressfs\
+	$U/_threads\
 	$U/_usertests\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
 
+
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
 
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..b4362d5 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -89,6 +89,7 @@ int             growproc(int);
 void            proc_mapstacks(pagetable_t);
 pagetable_t     proc_pagetable(struct proc *);
 void            proc_freepagetable(pagetable_t, uint64);
+void            thread_freepagetable(pagetable_t, uint64);
 int             kill(int);
 int             killed(struct proc*);
 void            setkilled(struct proc*);
@@ -99,6 +100,8 @@ void            procinit(void);
 void            scheduler(void) __attribute__((noreturn));
 void            sched(void);
 void            sleep(void*, struct spinlock*);
+void            thread_sleep(uint64);
+void            thread_wakeup(uint64);
 void            userinit(void);
 int             wait(uint64);
 void            wakeup(void*);
@@ -106,6 +109,9 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             create_thread(void(*fcn)(void*), void *arg, void *stack);
+int             join_thread(int thread_id);
+void            exit_thread(int);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -165,12 +171,16 @@ void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
+int             uvmgrow_mirror(pagetable_t, pagetable_t, uint64, uint64);
 void            uvmfree(pagetable_t, uint64);
+void            uvmfree_thread(pagetable_t, uint64);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
 pte_t *         walk(pagetable_t, uint64, int);
 uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
+int             thread_mutex_lk_release(pagetable_t, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
 
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..9a2cd18 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -15,6 +15,8 @@ struct proc *initproc;
 int nextpid = 1;
 struct spinlock pid_lock;
 
+struct spinlock memlocks[NPROC];
+
 extern void forkret(void);
 static void freeproc(struct proc *p);
 
@@ -56,6 +58,9 @@ procinit(void)
       p->state = UNUSED;
       p->kstack = KSTACK((int) (p - proc));
   }
+
+  for(int i = 0; i < NPROC; i++) // initializing the corresponding memlocks
+    initlock(&memlocks[i], "memlock");
 }
 
 // Must be called with interrupts disabled,
@@ -123,6 +128,11 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  // allocproc allocates from proc:a fixed array of processes
+  // the first unused process is allocated, so memlock should point to the
+  // memlock of this process
+  // thus memid is just the process index in proc array
+  p->mem_id = (uint64)(p - proc);
   p->state = USED;
 
   // Allocate a trapframe page.
@@ -146,6 +156,12 @@ found:
   p->context.ra = (uint64)forkret;
   p->context.sp = p->kstack + PGSIZE;
 
+  // not a thread
+  p->is_thread = 0;
+
+  // use memid to map memlock 
+  p->memlock = &memlocks[p->mem_id];
+
   return p;
 }
 
@@ -158,9 +174,24 @@ freeproc(struct proc *p)
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
-  if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+  if (!p->is_thread) {
+    if(p->pagetable ) { // free pagetable for process
+        acquire(p->memlock); // lock on pagetable modification
+        proc_freepagetable(p->pagetable, p->sz);
+        release(p->memlock); // release lock after pagetable modification
+    }
+  }
+  else {  // free pagetable for thread
+    if(p->pagetable) {
+      acquire(p->memlock); // lock on pagetable modification
+      thread_freepagetable(p->pagetable, p->sz);
+      release(p->memlock); // release lock after pagetable modification
+    }
+  }
+  
+  acquire(p->memlock); // lock on pagetable modification
   p->pagetable = 0;
+  release(p->memlock); // release lock after pagetable modification
   p->sz = 0;
   p->pid = 0;
   p->parent = 0;
@@ -169,6 +200,8 @@ freeproc(struct proc *p)
   p->killed = 0;
   p->xstate = 0;
   p->state = UNUSED;
+  p->is_thread = 0; // freeproc() call resets is_thread and mem_id
+  p->mem_id = -1; // allocproc() call would set it again
 }
 
 // Create a user page table for a given process, with no user memory,
@@ -215,6 +248,18 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz)
   uvmfree(pagetable, sz);
 }
 
+// thread's pagetables are freed
+// however no physical memory is released as
+// (uvmunmap call in uvmfree_thread has argument do_free=0) 
+// threads use parent address space
+void
+thread_freepagetable(pagetable_t pagetable, uint64 sz)
+{
+  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
+  uvmunmap(pagetable, TRAPFRAME, 1, 0);
+  uvmfree_thread(pagetable, sz);
+}
+
 // a user program that calls exec("/init")
 // assembled from ../user/initcode.S
 // od -t xC ../user/initcode
@@ -239,7 +284,9 @@ userinit(void)
   
   // allocate one user page and copy initcode's instructions
   // and data into it.
+  acquire(p->memlock); // lock on pagetable modification
   uvmfirst(p->pagetable, initcode, sizeof(initcode));
+  release(p->memlock); // release lock after pagetable modification
   p->sz = PGSIZE;
 
   // prepare for the very first "return" from kernel to user.
@@ -262,6 +309,8 @@ growproc(int n)
   uint64 sz;
   struct proc *p = myproc();
 
+  acquire(p->memlock); // lock this process/thread's common memlock
+
   sz = p->sz;
   if(n > 0){
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
@@ -271,6 +320,24 @@ growproc(int n)
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+
+  // shadow the changes in all the other threades/processes
+  // with same mem_id
+  // no (de)allocation, rather just map or unmap
+  for (struct proc *iter_p = proc; iter_p < &proc[NPROC]; iter_p++){
+    if (p != iter_p && p->mem_id == iter_p->mem_id){ // is a relative thread/process of p
+        if (n > 0) { // map the grown pages
+          uvmgrow_mirror(p->pagetable, iter_p->pagetable, iter_p->sz, sz);
+        } else if (n < 0) { // unmap pages in range (new_size, old_size)
+          // uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
+          uvmunmap(iter_p->pagetable, PGROUNDUP(sz), 
+                  (PGROUNDUP(iter_p->sz) - PGROUNDUP(sz)) / PGSIZE, 0);
+        }
+        iter_p->sz = sz;
+    }
+  } 
+
+  release(p->memlock); // release only after every relative is changed
   return 0;
 }
 
@@ -287,14 +354,19 @@ fork(void)
   if((np = allocproc()) == 0){
     return -1;
   }
-
+  
   // Copy user memory from parent to child.
+  // locking on memlock, even though np->lock is already held
+  acquire(p->memlock); // lock on pagetable modification
+
   if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0){
     freeproc(np);
+    release(p->memlock); // release lock after pagetable modification
     release(&np->lock);
     return -1;
   }
   np->sz = p->sz;
+  release(p->memlock); // release lock after pagetable modification
 
   // copy saved user registers.
   *(np->trapframe) = *(p->trapframe);
@@ -378,6 +450,10 @@ exit(int status)
   p->xstate = status;
   p->state = ZOMBIE;
 
+  // reset memid to -1, otherwise next growproc may think it as child
+  // if the memlock[p->mem_id] access happens, #BUGSRC
+  p->mem_id = -1;
+
   release(&wait_lock);
 
   // Jump into the scheduler, never to return.
@@ -408,13 +484,17 @@ wait(uint64 addr)
         if(pp->state == ZOMBIE){
           // Found one.
           pid = pp->pid;
+          acquire(p->memlock); // lock on pagetable modification
           if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
                                   sizeof(pp->xstate)) < 0) {
+            release(p->memlock); // release lock after pagetable modification
             release(&pp->lock);
             release(&wait_lock);
             return -1;
           }
+          release(p->memlock); // release lock after pagetable modification
           freeproc(pp);
+          
           release(&pp->lock);
           release(&wait_lock);
           return pid;
@@ -561,6 +641,36 @@ sleep(void *chan, struct spinlock *lk)
   acquire(lk);
 }
 
+// atomically releases passed on mutext lock and suspends thread
+// mutex lock at lk_addr would be reacquired over in user space
+void thread_sleep(uint64 lk_addr)
+{
+  struct proc *p = myproc();
+  
+  // Must acquire p->lock in order to
+  // change p->state and then call sched.
+  // Once we hold p->lock, we can be
+  // guaranteed that we won't miss any wakeup
+  // (wakeup locks p->lock),
+  // so it's okay to release lk.
+
+  acquire(&p->lock);  //DOC: sleeplock1
+
+  // we reset value at lk_addr, in effect releasing the mutex lock
+  acquire(p->memlock);  // lock on pagetable modification
+  thread_mutex_lk_release(p->pagetable, lk_addr);
+  release(p->memlock);  // release after pagetable modification
+
+  // Go to sleep.
+  p->state = SLEEPING;
+
+  sched();
+
+  
+  // Reacquire original lock.
+  release(&p->lock);
+}
+
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
 void
@@ -579,6 +689,27 @@ wakeup(void *chan)
   }
 }
 
+// Wake up the thread with this pid 
+// loops over all threads(processes) anyway
+// (pids are unique, but not breaking after finding pid
+// as there is a lock on p)
+// Must be called without any p->lock.
+void
+thread_wakeup(uint64 pid)
+{
+  struct proc *p;
+
+  for(p = proc; p < &proc[NPROC]; p++) {
+    if(p != myproc()){
+      acquire(&p->lock);
+      if(p->state == SLEEPING && p->pid == pid) {
+        p->state = RUNNABLE;
+      }
+      release(&p->lock);
+    }
+  }
+}
+
 // Kill the process with the given pid.
 // The victim won't exit until it tries to return
 // to user space (see usertrap() in trap.c).
@@ -630,7 +761,10 @@ either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
 {
   struct proc *p = myproc();
   if(user_dst){
-    return copyout(p->pagetable, dst, src, len);
+    acquire(p->memlock); // lock on pagetable modification
+    int r = copyout(p->pagetable, dst, src, len);
+    release(p->memlock); // release lock after pagetable modification
+    return r;
   } else {
     memmove((char *)dst, src, len);
     return 0;
@@ -645,7 +779,10 @@ either_copyin(void *dst, int user_src, uint64 src, uint64 len)
 {
   struct proc *p = myproc();
   if(user_src){
-    return copyin(p->pagetable, dst, src, len);
+    acquire(p->memlock); // lock on pagetable modification
+    int r = copyin(p->pagetable, dst, src, len);
+    release(p->memlock); // release lock after pagetable modification
+    return r;
   } else {
     memmove(dst, (char*)src, len);
     return 0;
@@ -681,3 +818,194 @@ procdump(void)
     printf("\n");
   }
 }
+
+// create a thread
+// the arguments are:
+// void(*fcn)(void*): the function pointer where execution would start
+// void* arg: argument to the function pointer
+// void* stack: the stack pointer of this thread
+// returns threadid on succes, otherwise -1
+int
+create_thread(void(*fcn)(void*), void *arg, void *stack)
+{
+  int i, tid;
+  struct proc *np;
+  struct proc *p = myproc();
+  
+  // Allocate process that will be treated as thread.
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  // copy memid
+  np->mem_id = p->mem_id;
+  // copy parent memlock, allocproc had given it exact corresponding memlock
+  // need to change to parent memlock
+  np->memlock = &memlocks[np->mem_id];
+   
+  acquire(np->memlock); // lock on pagetable
+
+  // Copy user memory from parent to child.
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+  
+  release(np->memlock); // release lock on pagetable
+
+  np->sz = p->sz;
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+  // change program counter of thread to given function pointer fcn
+  np->trapframe->epc = (uint64)fcn;
+
+  // make thread sp point to top(first) of given stack
+  // page, and align to risc-v 16 byte alignment
+  // no guard page for now
+  np->trapframe->sp = (uint64)stack + PGSIZE;
+  np->trapframe->sp -= np->trapframe->sp % 16;
+
+  // copy argument of fcn to argument register a0 #BUGSRC
+  // may shift to exec.c:91-99 if not working
+  np->trapframe->a0 = (uint64) arg;
+  // np->trapframe->sp -= strlen(arg) + 1;
+  // np->trapframe->sp -= np->trapframe->sp % 16; // downshift and align new sp pointer
+  
+  // if(np->trapframe->sp < (uint64)stack) 
+  //   panic("create thread: stack overflow");
+    
+  // // use copyin to copy arg from user virtual addr   
+  // // int copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
+  // if(copyin(np->pagetable,(char*) np->trapframe->sp, (uint64) arg, strlen(arg)+1) < 0)
+  //   return -1;
+
+  // Cause fork to return 0 in the child.
+  // np->trapframe->a0 = 0;
+  
+  // fake return pc
+  np->trapframe->ra = 0xffffffff;
+
+  // set as thread
+  np->is_thread = 1;
+
+  // increment reference counts on open file descriptors.
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  tid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+  
+
+  return tid;
+}
+
+// Wait for a child process to exit and return its pid.
+// argument:
+// int thread_id: child thread thread_id
+// returns thread_id, else -1 if no child thread has given id
+int
+join_thread(int thread_id)
+{
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children with same thread_id
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->parent == p && pp->pid == thread_id){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          // dropping the status copying and related check, no need
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+    
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
+// Exit the current thread. Does not return.
+// An exited thread remains in the zombie state
+// until its parent calls wait().
+void
+exit_thread(int status)
+{
+  struct proc *p = myproc();
+
+  if(p == initproc)
+    panic("init exiting");
+
+  // Close all open files.
+  for(int fd = 0; fd < NOFILE; fd++){
+    if(p->ofile[fd]){
+      struct file *f = p->ofile[fd];
+      fileclose(f);
+      p->ofile[fd] = 0;
+    }
+  }
+
+  begin_op();
+  iput(p->cwd);
+  end_op();
+  p->cwd = 0;
+
+  acquire(&wait_lock);
+
+  // Give any children to init.
+  reparent(p);
+
+  // Parent might be sleeping in wait().
+  wakeup(p->parent);
+  
+  acquire(&p->lock);
+
+  p->xstate = status;
+  p->state = ZOMBIE;
+
+  // reset memid to -1, otherwise next growproc may think it as child
+  // if the memlock[p->mem_id] access happens, #BUGSRC
+  p->mem_id = -1;
+
+  release(&wait_lock);
+
+  // Jump into the scheduler, never to return.
+  sched();
+  panic("zombie exit");
+}
\ No newline at end of file
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..f951e1c 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,11 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  // all threads share same memlock with parent, so locking any before using 
+  // pagetable keeps others from modifying shared pagetable
+  struct spinlock *memlock;
+  int is_thread;               // if it is thread
+  // All threads will have the same physical pages as the mother, hence the same 
+  // memory ID
+  int mem_id;                  
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..b374b35 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,11 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_thread_release_sleep(void);
+extern uint64 sys_thread_wakeup(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +131,11 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create] sys_thread_create,
+[SYS_thread_join] sys_thread_join,
+[SYS_thread_exit] sys_thread_exit,
+[SYS_thread_release_sleep]  sys_thread_release_sleep,
+[SYS_thread_wakeup] sys_thread_wakeup,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..a5bea4b 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create   22
+#define SYS_thread_join 23
+#define SYS_thread_exit 24
+#define SYS_thread_release_sleep    25
+#define SYS_thread_wakeup   26
\ No newline at end of file
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..c5760f4 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,64 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+// create a thread
+// return thread_id if succeds, else -1
+uint64
+sys_thread_create(void) 
+{
+  uint64 fcn;
+  uint64 arg;
+  uint64 stack;
+  argaddr(0, &fcn);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+  
+  return create_thread((void*) fcn, (void*) arg, (void*) stack);
+}
+
+// Wait for a child thread to exit and return its pid.
+// Return thread_id on success, or -1 if this process has no children
+uint64 
+sys_thread_join(void)
+{
+  int tid;
+  argint(0, &tid);
+  return join_thread(tid);
+}
+
+// Exit the current thread.
+// An exited thread remains in the zombie state
+// until its parent calls wait().
+// it goes to scheduler directly so never returns
+uint64 
+sys_thread_exit(void)
+{
+  int tid;
+  argint(0, &tid);
+  exit_thread(tid);
+  return 0; // unreached
+}
+
+// atomically releases passed on mutex lock
+// and puts thread to sleep
+uint64
+sys_thread_release_sleep(void)
+{
+  uint64 lk_addr;
+  argaddr(0, &lk_addr);
+  
+  thread_sleep(lk_addr);
+
+  return 0;
+}
+
+// wakes up thread with given pid
+uint64
+sys_thread_wakeup(void)
+{
+  int tid;
+  argint(0, &tid);
+  thread_wakeup(tid);
+  return 0;
+}
\ No newline at end of file
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..2292868 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -296,6 +296,18 @@ uvmfree(pagetable_t pagetable, uint64 sz)
   freewalk(pagetable);
 }
 
+// Free user memory pages of thread
+// then free page-table pages
+// not freeing the actual physical memory pages 
+// as they are of parent
+void
+uvmfree_thread(pagetable_t pagetable, uint64 sz) 
+{
+  if(sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 0);
+  freewalk(pagetable);
+}
+
 // Given a parent process's page table, copy
 // its memory into a child's page table.
 // Copies both the page table and the
@@ -332,6 +344,79 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+// Given a parent process's page table, copy
+// its memory into a child thread's page table.
+// Copies both the page table and the
+// physical memory.
+// no new allocation as threads use parent address space
+// returns 0 on success, -1 on failure.
+// frees any allocated pages on failure.
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmmirror: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    // drop kalloc call as thread uses parent address space
+    // drop memmove call, no new alloc'd page to move memory to
+    // map parent page physical address to thread pagetable
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      kfree((void*)pa);
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+// Given a parent process's grown page table, copy
+// the grown memory pages into a child thread's page table.
+// the copied range is PGROUNDUP(old_sz) to new_sz
+// Copies both the page table and the
+// physical memory.
+// no new allocation as threads use parent address space
+// returns 0 on success, -1 on failure.
+// frees any allocated pages on failure.
+int
+uvmgrow_mirror(pagetable_t old, pagetable_t new, uint64 new_sz, uint64 old_sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = PGROUNDUP(old_sz); i < new_sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmgrow_mirror: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmgrow_mirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    // drop kalloc call as thread uses parent address space
+    // drop memmove call, no new alloc'd page to move memory to
+    // map parent page physical address to thread pagetable
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      kfree((void*)pa);
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
@@ -370,6 +455,28 @@ copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
   return 0;
 }
 
+// release the lock at virtual address lk_addr 
+// Return 0 on success, -1 on error.
+int
+thread_mutex_lk_release(pagetable_t pagetable, uint64 lk_addr)
+{
+  uint64 va0, pa0;
+
+  va0 = PGROUNDDOWN(lk_addr);
+  pa0 = walkaddr(pagetable, va0);
+  if(pa0 == 0)
+    return -1;
+
+  // barrier telling compiler to not move any loads/store past this line
+  // making sure lock release happens almost immediately 
+  // before thread suspension in thread_sleep() 
+  // (after releasing pagetable memlock)   
+  __sync_synchronize();
+  __sync_lock_release((uint8*)(pa0 + (lk_addr - va0)));
+
+  return 0;
+}
+
 // Copy from user to kernel.
 // Copy len bytes to dst from virtual address srcva in a given page table.
 // Return 0 on success, -1 on error.
diff --git a/user/mythread.h b/user/mythread.h
new file mode 100644
index 0000000..896166a
--- /dev/null
+++ b/user/mythread.h
@@ -0,0 +1,307 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+
+/*============================================================================*/
+struct thread_spinlock
+{
+    uint8 locked; // is lock held
+
+    // debugging
+    char *name;    // lock name
+    int owner_pid; // owning process/thread pid
+};
+
+void thread_spin_init(struct thread_spinlock *lk, char *name);
+void thread_spin_lock(struct thread_spinlock *lk);
+void thread_spin_unlock(struct thread_spinlock *lk);
+int holding_thread_spinlock(struct thread_spinlock *lk);
+
+
+/*============================================================================*/
+struct thread_mutex
+{
+    uint8 is_locked; // is mutex set
+
+    // debugging
+    char *name;    // mutex name
+    int owner_pid; // owner process/thread pid
+};
+
+void thread_mutex_init(struct thread_mutex *m, char *name);
+void thread_mutex_lock(struct thread_mutex *m);
+void thread_mutex_unlock(struct thread_mutex *m);
+int locked(struct thread_mutex *m);
+
+struct thread_mutex mlock;
+/*============================================================================*/
+
+void thread_spin_init(struct thread_spinlock *lk, char *name)
+{
+    lk->locked = 0;
+    lk->name = name;
+    lk->owner_pid = 0; // no process/thread gets pid = 0
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired
+// loops again to set owner pid
+void thread_spin_lock(struct thread_spinlock *lk)
+{
+    if (holding_thread_spinlock(lk))
+    {
+        printf("error thread_spin_lock: lock held\n");
+        exit(-1);
+    }
+    // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+    //   a5 = 1
+    //   s1 = &lk->locked
+    //   amoswap.w.aq a5, a5, (s1)
+    while (__sync_lock_test_and_set(&lk->locked, 1) != 0)
+        ;
+
+    // Tell the C compiler and the processor to not move loads or stores
+    // past this point, to ensure that the critical section's memory
+    // references happen strictly after the lock is acquired.
+    // On RISC-V, this emits a fence instruction.
+    __sync_synchronize();
+
+    // Record info about lock acquisition for holding() and debugging.
+    int pid = getpid();
+    int old_pid = lk->owner_pid;
+    while (__sync_lock_test_and_set(&lk->owner_pid, pid) != old_pid)
+        ;
+}
+
+// release lock
+void thread_spin_unlock(struct thread_spinlock *lk)
+{
+    if (!holding_thread_spinlock(lk))
+    {
+        printf("error thread_spin_unlock: lock not held\n");
+        exit(-1);
+    }
+
+    // void __sync_lock_release (type *ptr, ...)
+    // releases the lock acquired by __sync_lock_test_and_set.
+    // Normally this means writing the constant 0 to *ptr.
+    __sync_lock_release(&lk->owner_pid); // no process/thread gets pid = 0
+
+    // Tell the C compiler and the CPU to not move loads or stores
+    // past this point, to ensure that all the stores in the critical
+    // section are visible to other CPUs before the lock is released,
+    // and that loads in the critical section occur strictly before
+    // the lock is released.
+    // On RISC-V, this emits a fence instruction.
+    __sync_synchronize();
+
+    // Release the lock, equivalent to lk->locked = 0.
+    // This code doesn't use a C assignment, since the C standard
+    // implies that an assignment might be implemented with
+    // multiple store instructions.
+    // On RISC-V, sync_lock_release turns into an atomic swap:
+    //   s1 = &lk->locked
+    //   amoswap.w zero, zero, (s1)
+    __sync_lock_release(&lk->locked);
+}
+
+// Check whether this process/thread is holding the lock.
+int holding_thread_spinlock(struct thread_spinlock *lk)
+{
+    int r;
+    r = (lk->locked && lk->owner_pid == getpid());
+    return r;
+}
+
+/*============================================================================*/
+void thread_mutex_init(struct thread_mutex *m, char *name)
+{
+    m->is_locked = 0;
+    m->name = name;
+    m->owner_pid = 0; // no process/thread gets pid = 0
+}
+
+// locks and then sets owner_pid
+// both in yielding loops
+void thread_mutex_lock(struct thread_mutex *m)
+{
+    // check and yield cpu till lock is changed from 0 to 1
+    while (__sync_lock_test_and_set(&m->is_locked, 1) != 0)
+    {
+        sleep(1);
+    }
+
+    // check and yield cpu till owner_pid set(return value old pid on success)
+    // Record info about lock acquisition for holding() and debugging.
+    int pid = getpid();
+    int old_pid = m->owner_pid;
+    while (__sync_lock_test_and_set(&m->owner_pid, pid) != old_pid)
+    {
+        sleep(1);
+    }
+}
+
+// set mutex to 0
+// yielding loop to set owner_pid
+void thread_mutex_unlock(struct thread_mutex *m)
+{
+    if (!locked(m))
+    {
+        printf("error thread_mutex_unlock: lock not held\n");
+        exit(-1);
+    }
+
+    // void __sync_lock_release (type *ptr, ...)
+    // releases the lock acquired by __sync_lock_test_and_set.
+    // Normally this means writing the constant 0 to *ptr.
+    __sync_lock_release(&m->owner_pid);
+
+    // Tell the C compiler and the CPU to not move loads or stores
+    // past this point, to ensure that all the stores in the critical
+    // section are visible to other CPUs before the lock is released,
+    // and that loads in the critical section occur strictly before
+    // the lock is released.
+    // On RISC-V, this emits a fence instruction.
+    __sync_synchronize();
+
+    // Release the lock, equivalent to m->locked = 0.
+    // This code doesn't use a C assignment, since the C standard
+    // implies that an assignment might be implemented with
+    // multiple store instructions.
+    // On RISC-V, sync_lock_release turns into an atomic swap:
+    //   s1 = &m->locked
+    //   amoswap.w zero, zero, (s1)
+    __sync_lock_release(&m->is_locked);
+}
+
+// is mutex held
+int locked(struct thread_mutex *m)
+{
+    int r;
+    r = (m->is_locked && m->owner_pid == getpid());
+    return r;
+}
+
+/*============================================================================*/
+struct queue
+{
+    int arr[16];
+    int front;
+    int rear;
+    int size;
+};
+void queue_init(struct queue *q)
+{
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+}
+void push(struct queue *q, int x)
+{
+    if (q->size == 16)
+        return; // Max size 16 for now
+    q->arr[q->rear] = x;
+    q->rear = (q->rear + 1) % 16;
+    q->size++;
+}
+int front(struct queue *q)
+{
+    if (q->size == 0)
+        return -1;
+    return q->arr[q->front];
+}
+void pop(struct queue *q)
+{
+    if (q->size == 0)
+        return; // dont let queue size go negative
+    q->front = (q->front + 1) % 16;
+    q->size--;
+}
+
+/*============================================================================*/
+struct thread_cond_var
+{
+    struct queue *q;
+    struct thread_mutex qlock;
+};
+
+void thread_cv_init(struct thread_cond_var* cv, struct queue *q)
+{
+    queue_init(q);
+    cv->q = q;
+}
+
+// push calling thread to cond_var wait queue
+// then release mutex and suspend calling thread
+// atomically
+void thread_cv_wait(struct thread_cond_var *cv, struct thread_mutex *mlock)
+{
+    thread_mutex_lock(&cv->qlock);
+    push(cv->q, getpid());
+    thread_mutex_unlock(&cv->qlock);
+
+    // atomic mutex lock release and thread suspension
+    // as this is a release so resetting mlock.owner_pid
+    __sync_lock_release(&mlock->owner_pid);
+    thread_release_sleep(&mlock->is_locked);
+
+    // thread wakes up so
+    // relocking after thread_release_sleep() 
+    // had unlocked the mutex
+    thread_mutex_lock(mlock);
+
+    return;
+}
+
+// signal first thread in queue to wakeup
+void thread_cv_signal(struct thread_cond_var *cv)
+{
+    int thread_id;
+
+    thread_mutex_lock(&cv->qlock);
+    thread_id = front(cv->q);
+    thread_mutex_unlock(&cv->qlock);
+
+    // TODO
+    if (thread_id > 0) 
+        thread_wakeup(thread_id);
+    return;
+}
+/*============================================================================*/
+struct thread_sem
+{
+    int count;
+    struct thread_mutex semlock;
+    struct thread_cond_var cv;
+};
+
+int thread_sem_init(struct thread_sem *t_sem, int value, struct queue *q)
+{
+    t_sem->count = value;
+    thread_mutex_init(&t_sem->semlock, "sem_mutex");
+    thread_cv_init(&t_sem->cv, q);
+    return 0;
+}
+
+// increment semaphore and signal waiting threads
+void thread_sem_post(struct thread_sem *t_sem)
+{
+    thread_mutex_lock(&t_sem->semlock);
+    t_sem->count++;
+    thread_cv_signal(&t_sem->cv);
+    thread_mutex_unlock(&t_sem->semlock);
+}
+
+// wait till semaphore posted by other thread
+// then decrement semaphore
+void thread_sem_wait(struct thread_sem *t_sem)
+{
+    thread_mutex_lock(&t_sem->semlock);
+    while (t_sem->count == 0)
+    {
+        thread_cv_wait(&t_sem->cv, &t_sem->semlock);
+    }
+    
+    t_sem->count--;
+    thread_mutex_unlock(&t_sem->semlock);
+}
\ No newline at end of file
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..52bdb2e
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,110 @@
+#include "user/mythread.h"
+
+struct queue q;
+// a mutex object lock 
+struct thread_mutex mlock;
+// a semaphore object empty
+struct thread_sem empty_sem;
+// a semaphore object full
+struct thread_sem full_sem;
+// queues for semaphore.conditional_variable
+struct queue full_sem_cv_q;
+struct queue empty_sem_cv_q;
+
+struct thread_mutex outlock;
+
+void init_semaphore()
+{
+	// initialize mutex lock
+    thread_mutex_init(&mlock, "mlock");
+	// initialize semaphore empty with 5
+    thread_sem_init(&empty_sem, 5, &empty_sem_cv_q);
+	// initialize semaphore full with 0
+    thread_sem_init(&full_sem, 0, &full_sem_cv_q);
+    // printf lock
+    thread_mutex_init(&outlock, "outlock");
+}
+
+void ProducerFunc(void * arg)
+{	
+    thread_mutex_lock(&outlock);
+	printf("%s\n",(char*)arg);
+    thread_mutex_unlock(&outlock);
+
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore empty
+        thread_sem_wait(&empty_sem);
+		// wait for mutex lock
+		thread_mutex_lock(&mlock);
+
+		sleep(1);	
+		push(&q, i);
+		
+        thread_mutex_lock(&outlock);
+	    printf("producer produced item %d\n",i);
+		thread_mutex_unlock(&outlock);
+
+		// unlock mutex lock
+        thread_mutex_unlock(&mlock);
+		// post semaphore full
+        thread_sem_post(&full_sem);
+	}
+    thread_exit();
+}
+
+void ConsumerFunc(void * arg)
+{
+	thread_mutex_lock(&outlock);
+	printf("%s\n",(char*)arg);
+    thread_mutex_unlock(&outlock);
+    
+    int i;
+	for(i=1;i<=10;i++)
+	{	
+		// wait for semphore full
+        thread_sem_wait(&full_sem);
+		// wait for mutex lock
+ 		thread_mutex_lock(&mlock);
+			
+		sleep(1);
+		int item = front(&q);
+		pop(&q);
+		
+        thread_mutex_lock(&outlock);
+	    printf("consumer consumed item %d\n",item);	
+        thread_mutex_unlock(&outlock);
+
+		// unlock mutex lock
+        thread_mutex_unlock(&mlock);
+		// post semaphore empty	
+        thread_sem_post(&empty_sem);	
+	}
+    thread_exit();
+}
+
+int main(void)
+{	
+	queue_init(&q);
+	init_semaphore();
+	
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void *s1, *s2;
+  	int thread1, thread2, r1, r2;
+
+  	s1 = malloc(4096);
+  	s2 = malloc(4096);
+
+  	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+  	thread2 = thread_create(ConsumerFunc, (void*)message2, s2); 
+
+  	r1 = thread_join(thread1);
+  	r2 = thread_join(thread2);	
+
+	printf("threads done: %d:(%d), %d:(%d)\n", thread1, r1, thread2, r2);
+	exit(0);
+}
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..db7ef6d
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,78 @@
+#include "user/mythread.h"
+
+struct thread_spinlock lock;
+struct thread_spinlock out_lock;
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+volatile int total_balance = 0;
+
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i; 
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;   
+}
+
+void do_work(void *arg){
+    int i; 
+    int old;
+   
+    struct balance *b = (struct balance*) arg; 
+    thread_spin_lock(&out_lock);
+    printf( "Starting do_work: s:%s\n", b->name);
+    thread_spin_unlock(&out_lock);
+
+    for (i = 0; i < b->amount; i++) { 
+        // lock and mlock will be implemented by you.
+         thread_spin_lock(&lock);
+        //  thread_mutex_lock(&mlock);
+         old = total_balance;
+         delay(100000);
+	 // if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+         total_balance = old + 1;
+         thread_spin_unlock(&lock);
+        //  thread_mutex_unlock(&mlock);
+
+    }
+  
+    thread_spin_lock(&out_lock);
+    printf( "Done s:%s\n", b->name);
+    thread_spin_unlock(&out_lock);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+
+  struct balance b1 = {"b1", 3200};
+  struct balance b2 = {"b2", 2800};
+ 
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  s2 = malloc(4096);
+
+//   thread_spin_init(&lock, "thread spinlock");
+  thread_spin_init(&out_lock, "print_lock");
+  thread_mutex_init(&mlock, "mutex");
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+  thread2 = thread_create(do_work, (void*)&b2, s2); 
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+  
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n", 
+      thread1, r1, thread2, r2, total_balance);
+
+  exit(0);
+}
+
diff --git a/user/user.h b/user/user.h
index 4d398d5..8d01c87 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack); // thread syscalls
+int thread_join(int thread_id); // thread syscalls
+void thread_exit(void); // thread syscalls
+int thread_release_sleep(uint8*); // thread syscalls
+int thread_wakeup(int); // thread syscalls
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..a0cb61b 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
+entry("thread_release_sleep");
+entry("thread_wakeup");
\ No newline at end of file
